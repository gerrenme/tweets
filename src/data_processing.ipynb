{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8c3cac-2552-44af-84d4-38c7f53b697d",
   "metadata": {},
   "source": [
    "# Modules Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d691e3-3bfc-4ecf-9ae6-6398b0be8f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63 µs, sys: 0 ns, total: 63 µs\n",
      "Wall time: 66 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from nltk import word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ad69b-e649-4198-91f3-3d53f42d38c1",
   "metadata": {},
   "source": [
    "# Preparing the Environment and Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a478974-af3b-43b2-9f31-3ced19e936a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gerrenme/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 12.4 ms, total: 275 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "    \n",
    "stemmer: PorterStemmer = PorterStemmer()\n",
    "spell: Speller = Speller(lang=\"en\")\n",
    "tfidf_vect: TfidfVectorizer = TfidfVectorizer()\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words: set[str] = set(stopwords.words(\"english\"))\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "try:\n",
    "    subprocess.check_output([\"python3\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "except Exception as e:\n",
    "    subprocess.check_output([\"python3\", \"-m\", \"download\", \"en_core_web_sm\"])\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa03dc-caee-455a-a36a-0d5e7fe45516",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496a5269-81f3-40e1-bcae-7ff1f5e1b773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how unhappy  some dogs like it though</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talking to my over driver about where i'm goin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>does anybody know if the rand's likely to fall...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets      mood\n",
       "0              how unhappy  some dogs like it though  negative\n",
       "1  talking to my over driver about where i'm goin...  negative\n",
       "2  does anybody know if the rand's likely to fall...  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 0 ns, total: 221 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def df_preprocessing(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"The method reads the dataframe and converts it to a readable form\"\"\"\n",
    "    new_df: pd.DataFrame = pd.read_csv(filepath)\n",
    "    new_df = new_df.T\n",
    "\n",
    "    new_df.reset_index(inplace=True)\n",
    "    new_df.columns = [\"tweets\"]\n",
    "    new_df[\"tweets\"] = new_df[\"tweets\"].apply(lambda words: words.lower())\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "negative_df: pd.DataFrame = df_preprocessing(\"datasets/processedNegative.csv\")\n",
    "positive_df: pd.DataFrame = df_preprocessing(\"datasets/processedPositive.csv\")\n",
    "neutral_df: pd.DataFrame = df_preprocessing(\"datasets/processedNeutral.csv\")\n",
    "\n",
    "negative_df[\"mood\"] = \"negative\"\n",
    "positive_df[\"mood\"] = \"positive\"\n",
    "neutral_df[\"mood\"] = \"neutral\"\n",
    "\n",
    "tweets_df: pd.DataFrame = pd.concat([neutral_df, positive_df, negative_df])\n",
    "\n",
    "display(negative_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aec433c-a99a-4434-b98b-ae555cee4212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'shocked' by hc order on handover to cbi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up cm bans paan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone me and harry have just had pancak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood\n",
       "0           'shocked' by hc order on handover to cbi     0\n",
       "1                                    up cm bans paan     0\n",
       "2  hey everyone me and harry have just had pancak...     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.98 ms, sys: 945 µs, total: 5.92 ms\n",
      "Wall time: 7.62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def convert_target_to_numeric(label):\n",
    "    \"\"\"The method converts the emotional connotation of a tweet from a string entry to a numeric one\"\"\"\n",
    "    if label == \"positive\":\n",
    "        return 1\n",
    "    elif label == \"negative\":\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "tweets_df = tweets_df.sample(frac=1).reset_index(drop=True)\n",
    "tweets_df[\"mood\"] = tweets_df[\"mood\"].apply(convert_target_to_numeric)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1a85f5-0b08-4f0e-b3a9-29a636d663fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked by hc order on handover to cbi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up cm bans paan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone me and harry have just had pancak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood\n",
       "0             shocked by hc order on handover to cbi     0\n",
       "1                                    up cm bans paan     0\n",
       "2  hey everyone me and harry have just had pancak...     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.7 ms, sys: 1.66 ms, total: 7.37 ms\n",
      "Wall time: 7.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"The method leaves only letters and spaces, removing digits and punctuation marks\"\"\"\n",
    "    return re.sub(r\"[^a-zA-Z\\s]+\", \"\", text)\n",
    "\n",
    "\n",
    "tweets_df[\"tweets\"] = tweets_df[\"tweets\"].apply(remove_punctuation)\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deac0c2e-5292-423b-b8f9-041a1a62919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood\n",
       "0                      shocked hc order handover cbi     0\n",
       "1                                       cm bans paan     0\n",
       "2  hey everyone harry pancakes maple syrup breakf...     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def drop_stop_words(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Method removes stop words\"\"\"\n",
    "    df[\"tweets\"] = df[\"tweets\"].apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))\n",
    "    return df\n",
    "\n",
    "tweets_df = drop_stop_words(tweets_df)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7297ae75-9808-4f38-9c42-1b7e4b265435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \n",
       "0                [shocked, hc, order, handover, cbi]  \n",
       "1                                   [cm, bans, paan]  \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 127 ms, sys: 1.7 ms, total: 129 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_tokens(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method converts the text of a tweet into tokens (individual words)\"\"\"\n",
    "    df[\"tokens\"] = df[\"tweets\"].apply(word_tokenize)\n",
    "    return df\n",
    "\n",
    "\n",
    "tweets_df = add_tokens(tweets_df)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b5a7b3-40ab-40ad-907c-c23762b5bb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0                          shock hc order handov cbi  \n",
       "1                                        cm ban paan  \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 0 ns, total: 140 ms\n",
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_stemming(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method performs stemming over the tokens and merges them into a single text\"\"\"\n",
    "    if \"tokens\" not in df.columns:\n",
    "        df = add_tokens(df)\n",
    "        \n",
    "    df[\"stemmed_text\"] = df[\"tokens\"].apply(lambda words: [stemmer.stem(word) for word in words])\n",
    "    df[\"stemmed_text\"] = df[\"stemmed_text\"].apply(lambda row: \" \".join(row))\n",
    "    return df\n",
    "\n",
    "\n",
    "tweets_df = add_stemming(tweets_df)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330ba88c-a890-49f6-ba0c-302efe8ed842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0                        shock hc order handover cbi  \n",
       "1                                        cm ban paan  \n",
       "2  hey everyone harry pancakes maple syrup breakf...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.67 s, sys: 0 ns, total: 8.67 s\n",
      "Wall time: 8.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_lemma(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method performs lemmatization over the tokens and merges them into a single text\"\"\"\n",
    "    if \"tokens\" not in df.columns:\n",
    "        df = add_tokens(df)\n",
    "\n",
    "    df[\"lemmatized_text\"] = df[\"tokens\"].apply(lambda words: [token.lemma_ for token in nlp(\" \".join(words))])\n",
    "    df[\"lemmatized_text\"] = df[\"lemmatized_text\"].apply(lambda row: \" \".join(row))\n",
    "    return df\n",
    "\n",
    "\n",
    "tweets_df = add_lemma(tweets_df)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe098f1-ee61-4767-8e45-6853df5115c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>misspell_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm bans plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyone harry pancakes maple syrup breakf...   \n",
       "\n",
       "                                       misspell_text  \n",
       "0                      shocked hc order handover cbi  \n",
       "1                                       cm bans plan  \n",
       "2  hey everyone harry pancake maple syrup breakfa...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 0 ns, total: 35.1 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_misspellings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method performs misspelling over the tokens and merges them into a single text\"\"\"\n",
    "    if \"tokens\" not in df.columns:\n",
    "        df = add_tokens(df)\n",
    "        \n",
    "    df[\"misspell_text\"] = df[\"tokens\"].apply(lambda words: [spell(word) for word in words])\n",
    "    df[\"misspell_text\"] = df[\"misspell_text\"].apply(lambda row: \" \".join(row))\n",
    "    return df\n",
    "\n",
    "\n",
    "tweets_df = add_misspellings(tweets_df)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b0a545-2033-45ff-b0ae-92c5c191a8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>misspell_text</th>\n",
       "      <th>lemma_misspell_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm bans plan</td>\n",
       "      <td>cm ban plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyone harry pancakes maple syrup breakf...   \n",
       "\n",
       "                                       misspell_text  \\\n",
       "0                      shocked hc order handover cbi   \n",
       "1                                       cm bans plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                 lemma_misspell_text  \n",
       "0                        shock hc order handover cbi  \n",
       "1                                        cm ban plan  \n",
       "2  hey everyone harry pancake maple syrup breakfa...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 0 ns, total: 35.7 s\n",
      "Wall time: 35.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_lemma_misspellings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method performs lemmatization and misspelling over the tokens and merges them into a single text\"\"\"\n",
    "    if \"lemmatized_text\" not in df.columns:\n",
    "        df = add_lemma(df)\n",
    "        \n",
    "    df[\"lemma_misspell_text\"] = df[\"lemmatized_text\"].apply(lambda words: [spell(word) for word in words.split()])\n",
    "    df[\"lemma_misspell_text\"] = df[\"lemma_misspell_text\"].apply(lambda row: \" \".join(row))\n",
    "    return df\n",
    "\n",
    "\n",
    "tweets_df = add_lemma_misspellings(tweets_df)\n",
    "\n",
    "display(tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51191e23-35b1-432b-ad0c-a19325cad57f",
   "metadata": {},
   "source": [
    "# Creating a Bag Of Words and Adding New Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5ca7a3a-a375-49b7-aecb-d75ada8cceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>misspell_text</th>\n",
       "      <th>lemma_misspell_text</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaa</th>\n",
       "      <th>aaffaa</th>\n",
       "      <th>...</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yuri</th>\n",
       "      <th>zabardast</th>\n",
       "      <th>zac</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm bans plan</td>\n",
       "      <td>cm ban plan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyone harry pancakes maple syrup breakf...   \n",
       "\n",
       "                                       misspell_text  \\\n",
       "0                      shocked hc order handover cbi   \n",
       "1                                       cm bans plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                 lemma_misspell_text  aa  aaaaaa  aaffaa  ...  \\\n",
       "0                        shock hc order handover cbi   0       0       0  ...   \n",
       "1                                        cm ban plan   0       0       0  ...   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   0       0       0  ...   \n",
       "\n",
       "   yoyoyou  yr  yrs  yuri  zabardast  zac  zealand  zero  zoo  zoos  \n",
       "0        0   0    0     0          0    0        0     0    0     0  \n",
       "1        0   0    0     0          0    0        0     0    0     0  \n",
       "2        0   1    0     0          0    0        0     0    0     0  \n",
       "\n",
       "[3 rows x 5756 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.34 s, sys: 15.5 ms, total: 6.35 s\n",
      "Wall time: 6.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_bag_of_words(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Method returns a bag of words consisting of all words \n",
    "    of the \"misspell_text\" attribute\"\"\"\n",
    "    bag: list[str] = []\n",
    "    if \"misspell_text\" in df.columns:\n",
    "        words: set[str] = set([token.strip() for tokens in df[\"misspell_text\"].values for token in tokens.split()])\n",
    "        bag = sorted(words)\n",
    "    \n",
    "    return bag\n",
    "\n",
    "\n",
    "def add_binary_words(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method creates a new attribute from each word in the word \n",
    "    bag and populates it with 1 if the word occurs in the \"misspell_text\" \n",
    "    attribute and 0 if it does not\"\"\"\n",
    "    bag_of_words: list[str] = get_bag_of_words(df)\n",
    "    for col in df.columns:\n",
    "        if col in bag_of_words:\n",
    "            bag_of_words.remove(col)\n",
    "    \n",
    "    for word in bag_of_words:\n",
    "        df[word] = df[\"misspell_text\"].apply(lambda row: 1 if word in row else 0)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "binary_tweets_df: pd.DataFrame = tweets_df.copy()\n",
    "binary_tweets_df = add_binary_words(binary_tweets_df)\n",
    "\n",
    "display(binary_tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35eee1a8-741b-4382-ac4a-1680a6aed04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>misspell_text</th>\n",
       "      <th>lemma_misspell_text</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaa</th>\n",
       "      <th>aaffaa</th>\n",
       "      <th>...</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yuri</th>\n",
       "      <th>zabardast</th>\n",
       "      <th>zac</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm bans plan</td>\n",
       "      <td>cm ban plan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyone harry pancakes maple syrup breakf...   \n",
       "\n",
       "                                       misspell_text  \\\n",
       "0                      shocked hc order handover cbi   \n",
       "1                                       cm bans plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                 lemma_misspell_text  aa  aaaaaa  aaffaa  ...  \\\n",
       "0                        shock hc order handover cbi   0       0       0  ...   \n",
       "1                                        cm ban plan   0       0       0  ...   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   0       0       0  ...   \n",
       "\n",
       "   yoyoyou  yr  yrs  yuri  zabardast  zac  zealand  zero  zoo  zoos  \n",
       "0        0   0    0     0          0    0        0     0    0     0  \n",
       "1        0   0    0     0          0    0        0     0    0     0  \n",
       "2        0   1    0     0          0    0        0     0    0     0  \n",
       "\n",
       "[3 rows x 5756 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.59 s, sys: 67.8 ms, total: 6.66 s\n",
      "Wall time: 6.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_words_count(df: pd.DataFrame) -> pd.DataFrame: \n",
    "    \"\"\"The method creates a new attribute from each word in the word bag and \n",
    "    fills it with a number equal to the number of times that the word \n",
    "    occurs in the \"misspell_text\" attribute for this entry\"\"\"\n",
    "    bag_of_words: list[str] = get_bag_of_words(df)\n",
    "    for col in df.columns:\n",
    "        if col in bag_of_words:\n",
    "            bag_of_words.remove(col)\n",
    "        \n",
    "    for word in bag_of_words:\n",
    "        df[word] = df[\"misspell_text\"].apply(lambda row: row.count(word))\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "count_tweets_df: pd.DataFrame = tweets_df.copy()\n",
    "count_tweets_df = add_words_count(count_tweets_df)\n",
    "\n",
    "display(count_tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1f1bfa-dd5b-439e-a554-23a8256a5497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>misspell_text</th>\n",
       "      <th>lemma_misspell_text</th>\n",
       "      <th>words_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm bans plan</td>\n",
       "      <td>cm ban plan</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyone harry pancakes maple syrup breakf...   \n",
       "\n",
       "                                       misspell_text  \\\n",
       "0                      shocked hc order handover cbi   \n",
       "1                                       cm bans plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                 lemma_misspell_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                         words_tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 ms, sys: 232 ms, total: 503 ms\n",
      "Wall time: 505 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_tfidf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The method adds a \"words_tfidf\" column that contains the tfidf representation \n",
    "    for the \"misspell_text\" attribute of this record\"\"\"\n",
    "    tfidf_matrix = tfidf_vect.fit_transform(df[\"misspell_text\"])\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n",
    "                            columns=tfidf_vect.get_feature_names_out(), index=df.index)\n",
    "\n",
    "    df[\"words_tfidf\"] = tfidf_df.values.tolist()\n",
    "    return df\n",
    "\n",
    "\n",
    "tfidf_tweets_df: pd.DataFrame = tweets_df.copy()\n",
    "tfidf_tweets_df = add_tfidf(tfidf_tweets_df)\n",
    "\n",
    "display(tfidf_tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38adcabf-e757-4655-86b8-b704e3738ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>mood</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>misspell_text</th>\n",
       "      <th>lemma_misspell_text</th>\n",
       "      <th>words_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[shocked, hc, order, handover, cbi]</td>\n",
       "      <td>shock hc order handov cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>shocked hc order handover cbi</td>\n",
       "      <td>shock hc order handover cbi</td>\n",
       "      <td>[0.6803466, 0.7310252, 0.17579159, 0.11130236,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm bans paan</td>\n",
       "      <td>0</td>\n",
       "      <td>[cm, bans, paan]</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm ban paan</td>\n",
       "      <td>cm bans plan</td>\n",
       "      <td>cm ban plan</td>\n",
       "      <td>[0.6536197, 1.1341192, 0.44983387, -0.2060052,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, everyone, harry, pancakes, maple, syrup,...</td>\n",
       "      <td>hey everyon harri pancak mapl syrup breakfast ...</td>\n",
       "      <td>hey everyone harry pancakes maple syrup breakf...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>hey everyone harry pancake maple syrup breakfa...</td>\n",
       "      <td>[-1.2848617, 0.18830332, 0.31929505, -0.090066...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  mood  \\\n",
       "0                      shocked hc order handover cbi     0   \n",
       "1                                       cm bans paan     0   \n",
       "2  hey everyone harry pancakes maple syrup breakf...     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [shocked, hc, order, handover, cbi]   \n",
       "1                                   [cm, bans, paan]   \n",
       "2  [hey, everyone, harry, pancakes, maple, syrup,...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                          shock hc order handov cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyon harri pancak mapl syrup breakfast ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban paan   \n",
       "2  hey everyone harry pancakes maple syrup breakf...   \n",
       "\n",
       "                                       misspell_text  \\\n",
       "0                      shocked hc order handover cbi   \n",
       "1                                       cm bans plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                 lemma_misspell_text  \\\n",
       "0                        shock hc order handover cbi   \n",
       "1                                        cm ban plan   \n",
       "2  hey everyone harry pancake maple syrup breakfa...   \n",
       "\n",
       "                                      words_word2vec  \n",
       "0  [0.6803466, 0.7310252, 0.17579159, 0.11130236,...  \n",
       "1  [0.6536197, 1.1341192, 0.44983387, -0.2060052,...  \n",
       "2  [-1.2848617, 0.18830332, 0.31929505, -0.090066...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 35.6 ms, total: 1.19 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_word2vec(df: pd.DataFrame, vector_size: int = 100, min_count: int = 1, \n",
    "                 window: int = 5, epochs: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"The method adds a \"words_word2vec\" column that contains the word2vec representation \n",
    "    for the \"misspell_text\" attribute of this record\"\"\"\n",
    "    \n",
    "    sentences = [text.split() for text in df[\"misspell_text\"]]\n",
    "    model = Word2Vec(sentences, vector_size=vector_size, min_count=min_count, \n",
    "                     window=window, epochs=epochs)\n",
    "\n",
    "    word2vec_vectors = []\n",
    "    for text in sentences:\n",
    "        if len(text) > 0:\n",
    "            vector = sum(model.wv[word] for word in text if word in model.wv) / len(text)\n",
    "        else:\n",
    "            vector = [0] * vector_size \n",
    "        word2vec_vectors.append(vector)\n",
    "\n",
    "    df[\"words_word2vec\"] = word2vec_vectors\n",
    "    return df\n",
    "\n",
    "\n",
    "w2v_tweets_df: pd.DataFrame = tweets_df.copy()\n",
    "w2v_tweets_df = add_word2vec(w2v_tweets_df)\n",
    "\n",
    "display(w2v_tweets_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0249d-d739-4f97-86aa-134ed16f4c59",
   "metadata": {},
   "source": [
    "# Binary DF Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d7d35ba-0c57-43c6-bf04-524ddf3e669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 389 ms, sys: 59.7 ms, total: 448 ms\n",
      "Wall time: 450 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X: pd.DataFrame = binary_tweets_df.iloc[:, 7:]\n",
    "y: pd.Series = binary_tweets_df[\"mood\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "pred_results: dict[str, float] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ac62c5-41c2-4079-be1c-cf86012bd53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 299 ms, sys: 23.9 ms, total: 322 ms\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rand_for: RandomForestClassifier = RandomForestClassifier(random_state=21, n_estimators=100, max_depth=4)\n",
    "\n",
    "rand_for.fit(X_train, y_train)\n",
    "y_pred_rf = rand_for.predict(X_test)\n",
    "\n",
    "pred_results[\"rand_for_accur_bin\"] = accuracy_score(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mae_bin\"] = mean_absolute_error(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mrse_bin\"] = np.sqrt(mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d577d402-924b-4398-999f-0c397bc80692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 28.6 s, total: 51.6 s\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg: LogisticRegression = LogisticRegression(random_state=21, solver=\"lbfgs\", max_iter=500)\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "pred_results[\"log_reg_accur_bin\"] = accuracy_score(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mae_bin\"] = mean_absolute_error(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mrse_bin\"] = np.sqrt(mean_squared_error(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85ded022-aa30-4ad1-bded-3cb3968b8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction type rand_for_accur_bin; Value -- 0.7729032258064517\n",
      "Prediction type rand_for_mae_bin; Value -- 0.2503225806451613\n",
      "Prediction type rand_for_mrse_bin; Value -- 0.5447698537441175\n",
      "Prediction type log_reg_accur_bin; Value -- 0.8825806451612903\n",
      "Prediction type log_reg_mae_bin; Value -- 0.15096774193548387\n",
      "Prediction type log_reg_mrse_bin; Value -- 0.46697378526961475\n"
     ]
    }
   ],
   "source": [
    "for pred_type in pred_results:\n",
    "    print(f\"Prediction type {pred_type}; Value -- {pred_results[pred_type]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24cd7a-e792-4292-aaa1-2dfec566605a",
   "metadata": {},
   "source": [
    "# Count DF Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a171d86-cee5-4239-b770-897149cc8aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 884 ms, sys: 1.23 s, total: 2.12 s\n",
      "Wall time: 461 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X: pd.DataFrame = count_tweets_df.iloc[:, 7:]\n",
    "y: pd.Series = count_tweets_df[\"mood\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "277ef080-de74-4dcd-bdce-c1dc61398980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 596 ms, sys: 12.2 ms, total: 608 ms\n",
      "Wall time: 608 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rand_for: RandomForestClassifier = RandomForestClassifier(random_state=21, n_estimators=50, max_depth=22)\n",
    "\n",
    "rand_for.fit(X_train, y_train)\n",
    "y_pred_rf = rand_for.predict(X_test)\n",
    "\n",
    "pred_results[\"rand_for_accur_cnt\"] = accuracy_score(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mae_cnt\"] = mean_absolute_error(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mrse_cnt\"] = np.sqrt(mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99c1b618-ab2d-45a4-96ca-ec4e01f3a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.1 s, sys: 1min, total: 1min 42s\n",
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg: LogisticRegression = LogisticRegression(random_state=21, solver=\"lbfgs\", max_iter=500)\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "pred_results[\"log_reg_accur_cnt\"] = accuracy_score(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mae_cnt\"] = mean_absolute_error(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mrse_cnt\"] = np.sqrt(mean_squared_error(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c3120fe-a17c-4fd6-9301-e47363524041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction type rand_for_accur_bin; Value -- 0.7729032258064517\n",
      "Prediction type rand_for_mae_bin; Value -- 0.2503225806451613\n",
      "Prediction type rand_for_mrse_bin; Value -- 0.5447698537441175\n",
      "Prediction type log_reg_accur_bin; Value -- 0.8825806451612903\n",
      "Prediction type log_reg_mae_bin; Value -- 0.15096774193548387\n",
      "Prediction type log_reg_mrse_bin; Value -- 0.46697378526961475\n",
      "Prediction type rand_for_accur_cnt; Value -- 0.8374193548387097\n",
      "Prediction type rand_for_mae_cnt; Value -- 0.17290322580645162\n",
      "Prediction type rand_for_mrse_cnt; Value -- 0.43994134506405985\n",
      "Prediction type log_reg_accur_cnt; Value -- 0.8748387096774194\n",
      "Prediction type log_reg_mae_cnt; Value -- 0.16\n",
      "Prediction type log_reg_mrse_cnt; Value -- 0.47924672075543584\n"
     ]
    }
   ],
   "source": [
    "for pred_type in pred_results:\n",
    "    print(f\"Prediction type {pred_type}; Value -- {pred_results[pred_type]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaad36-76e2-47fe-ab1e-cbbdb48c8e4e",
   "metadata": {},
   "source": [
    "# TFIDF DF Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63a09ba8-daec-475d-8de6-853c4f7bf821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 127 ms, sys: 288 ms, total: 416 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X: pd.DataFrame = tfidf_tweets_df[\"words_tfidf\"].to_list()\n",
    "y: pd.Series = tfidf_tweets_df[\"mood\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3c73f95-2dce-4ab5-904e-7e84dae7dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 764 ms, total: 2.47 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rand_for: RandomForestClassifier = RandomForestClassifier(random_state=21, n_estimators=50, max_depth=22)\n",
    "\n",
    "rand_for.fit(X_train, y_train)\n",
    "y_pred_rf = rand_for.predict(X_test)\n",
    "\n",
    "pred_results[\"rand_for_accur_tfidf\"] = accuracy_score(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mae_tfidf\"] = mean_absolute_error(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mrse_tfidf\"] = np.sqrt(mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2f750c-c1d9-4acc-a6a4-2bbae2b1f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 19.1 s, total: 32.9 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg: LogisticRegression = LogisticRegression(random_state=21, solver=\"lbfgs\", max_iter=500)\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "pred_results[\"log_reg_accur_tfidf\"] = accuracy_score(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mae_tfidf\"] = mean_absolute_error(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mrse_tfidf\"] = np.sqrt(mean_squared_error(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35c5bd0c-4436-418b-b4f2-b6059e5d1f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction type rand_for_accur_bin; Value -- 0.7729032258064517\n",
      "Prediction type rand_for_mae_bin; Value -- 0.2503225806451613\n",
      "Prediction type rand_for_mrse_bin; Value -- 0.5447698537441175\n",
      "Prediction type log_reg_accur_bin; Value -- 0.8825806451612903\n",
      "Prediction type log_reg_mae_bin; Value -- 0.15096774193548387\n",
      "Prediction type log_reg_mrse_bin; Value -- 0.46697378526961475\n",
      "Prediction type rand_for_accur_cnt; Value -- 0.8374193548387097\n",
      "Prediction type rand_for_mae_cnt; Value -- 0.17290322580645162\n",
      "Prediction type rand_for_mrse_cnt; Value -- 0.43994134506405985\n",
      "Prediction type log_reg_accur_cnt; Value -- 0.8748387096774194\n",
      "Prediction type log_reg_mae_cnt; Value -- 0.16\n",
      "Prediction type log_reg_mrse_cnt; Value -- 0.47924672075543584\n",
      "Prediction type rand_for_accur_tfidf; Value -- 0.8425806451612903\n",
      "Prediction type rand_for_mae_tfidf; Value -- 0.16\n",
      "Prediction type rand_for_mrse_tfidf; Value -- 0.4064004064006096\n",
      "Prediction type log_reg_accur_tfidf; Value -- 0.8619354838709677\n",
      "Prediction type log_reg_mae_tfidf; Value -- 0.15483870967741936\n",
      "Prediction type log_reg_mrse_tfidf; Value -- 0.4340358242981719\n"
     ]
    }
   ],
   "source": [
    "for pred_type in pred_results:\n",
    "    print(f\"Prediction type {pred_type}; Value -- {pred_results[pred_type]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c9836-33e8-4423-9514-cac207840c8d",
   "metadata": {},
   "source": [
    "# Word2Vec Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbdb7cdf-28db-4f83-b0f8-8085bc05944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 ms, sys: 13.3 ms, total: 35.6 ms\n",
      "Wall time: 1.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X: pd.DataFrame = w2v_tweets_df[\"words_word2vec\"].to_list()\n",
    "y: pd.Series = w2v_tweets_df[\"mood\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "493a332e-37c3-46f4-9999-4686317079bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 1.13 s, total: 2.35 s\n",
      "Wall time: 880 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rand_for: RandomForestClassifier = RandomForestClassifier(random_state=21, n_estimators=50, max_depth=22)\n",
    "\n",
    "rand_for.fit(X_train, y_train)\n",
    "y_pred_rf = rand_for.predict(X_test)\n",
    "\n",
    "pred_results[\"rand_for_accur_w2v\"] = accuracy_score(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mae_w2v\"] = mean_absolute_error(y_test, y_pred_rf)\n",
    "pred_results[\"rand_for_mrse_w2v\"] = np.sqrt(mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc463ad0-b438-4d89-af1f-5ccb3b4326f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 665 ms, sys: 988 ms, total: 1.65 s\n",
      "Wall time: 95.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg: LogisticRegression = LogisticRegression(random_state=21, solver=\"lbfgs\", max_iter=500)\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "pred_results[\"log_reg_accur_w2v\"] = accuracy_score(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mae_w2v\"] = mean_absolute_error(y_test, y_pred_lr)\n",
    "pred_results[\"log_reg_mrse_w2v\"] = np.sqrt(mean_squared_error(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eae793be-41af-4625-9aaa-b79cc04890a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction type rand_for_accur_bin; Value -- 0.7729032258064517\n",
      "Prediction type rand_for_mae_bin; Value -- 0.2503225806451613\n",
      "Prediction type rand_for_mrse_bin; Value -- 0.5447698537441175\n",
      "Prediction type log_reg_accur_bin; Value -- 0.8825806451612903\n",
      "Prediction type log_reg_mae_bin; Value -- 0.15096774193548387\n",
      "Prediction type log_reg_mrse_bin; Value -- 0.46697378526961475\n",
      "Prediction type rand_for_accur_cnt; Value -- 0.8374193548387097\n",
      "Prediction type rand_for_mae_cnt; Value -- 0.17290322580645162\n",
      "Prediction type rand_for_mrse_cnt; Value -- 0.43994134506405985\n",
      "Prediction type log_reg_accur_cnt; Value -- 0.8748387096774194\n",
      "Prediction type log_reg_mae_cnt; Value -- 0.16\n",
      "Prediction type log_reg_mrse_cnt; Value -- 0.47924672075543584\n",
      "Prediction type rand_for_accur_tfidf; Value -- 0.8425806451612903\n",
      "Prediction type rand_for_mae_tfidf; Value -- 0.16\n",
      "Prediction type rand_for_mrse_tfidf; Value -- 0.4064004064006096\n",
      "Prediction type log_reg_accur_tfidf; Value -- 0.8619354838709677\n",
      "Prediction type log_reg_mae_tfidf; Value -- 0.15483870967741936\n",
      "Prediction type log_reg_mrse_tfidf; Value -- 0.4340358242981719\n",
      "Prediction type rand_for_accur_w2v; Value -- 0.8619354838709677\n",
      "Prediction type rand_for_mae_w2v; Value -- 0.19225806451612903\n",
      "Prediction type rand_for_mrse_w2v; Value -- 0.5483111901925061\n",
      "Prediction type log_reg_accur_w2v; Value -- 0.8774193548387097\n",
      "Prediction type log_reg_mae_w2v; Value -- 0.17548387096774193\n",
      "Prediction type log_reg_mrse_w2v; Value -- 0.5303681010210222\n"
     ]
    }
   ],
   "source": [
    "for pred_type in pred_results:\n",
    "    print(f\"Prediction type {pred_type}; Value -- {pred_results[pred_type]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823868e-b850-441d-a6c5-4604c5301f2f",
   "metadata": {},
   "source": [
    "# Find Most Simmilar Twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c7d9e23-d242-4457-924a-63c9de6f7e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее похожие записи на 'shock hc order handover cbi':\n",
      "calcutta hc send case cbi\n",
      "rahul meet hc give cbi\n",
      "supreme court term unfortunate ground cite bengal govt plea hc order ask cbi take case\n",
      "that s shock evil unhappy\n",
      "order ban\n",
      "cbi book leader case\n",
      "sc hear petition challenge bombay hc order beef ban\n",
      "judge sc bench hear plea mara hc justice order stay transfer early\n",
      "order car yesterday\n",
      "\n",
      "Наиболее похожие записи на 'cm ban plan':\n",
      "chief minister ban plan masala\n",
      "order ban\n",
      "sc ban\n",
      "will not ban\n",
      "pay hike plan\n",
      "want fun plan weekend unhappy\n",
      "bypass highway ban\n",
      "ban ja hero\n",
      "plan cap fee\n",
      "\n",
      "Наиболее похожие записи на 'hey everyone harry pancake maple syrup breakfast great way start day happy miss':\n",
      "great day everyone happy\n",
      "good day hey happy\n",
      "happy everyone happy\n",
      "way\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "great day today happy\n",
      "\n",
      "Наиболее похожие записи на 'welfare':\n",
      "supreme court say welfare scheme proof\n",
      "government can not make mandatory extend benefit welfare scheme\n",
      "agitation delay day trouble soon come\n",
      "hope louis get time want come back fresh happy happy\n",
      "can not deathmatch piss unhappy\n",
      "stay hour phone ad bubbyyyyyyy miss unhappy\n",
      "scientist build case bite\n",
      "russell phone possibility chance would notice unhappy\n",
      "thank happy\n",
      "\n",
      "Наиболее похожие записи на 'guy please help try smoke lettuce early salad ruin unhappy':\n",
      "guy please help between unhappy\n",
      "guy please help between unhappy\n",
      "early\n",
      "early\n",
      "need help guy cry\n",
      "early happy\n",
      "please unhappy\n",
      "help unhappy early birthday gift huh\n",
      "malik salad\n",
      "\n",
      "Наиболее похожие записи на 'thank share iris photo really appreciate smile':\n",
      "thank share iris photo really appreciate smile\n",
      "thank share happy\n",
      "thank share happy\n",
      "thank much smile\n",
      "smile\n",
      "I m get one smile smile smile smile\n",
      "I m really happy\n",
      "really appreciate hope brilliant day happy\n",
      "much appreciate happy\n",
      "\n",
      "Наиболее похожие записи на 'year old comment new ladylike videos trust troll':\n",
      "old unhappy\n",
      "year\n",
      "year\n",
      "year\n",
      "year\n",
      "trust vote\n",
      "can not believe year next year unhappy become old hahahah v\n",
      "modes comment\n",
      "see hope comment\n",
      "\n",
      "Наиболее похожие записи на 'congratulations impressive happy':\n",
      "congratulations happy\n",
      "congratulations\n",
      "congratulations world happy\n",
      "congratulations david well do mrs v welcome jessica happy\n",
      "www fungi do not see win today sad congratulations winner\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "\n",
      "Наиболее похожие записи на 'thank recent follow happy connect happy great thursday':\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "thank recent follow happy connect happy great thursday\n",
      "\n",
      "Наиболее похожие записи на 'body hear everything mind say kind':\n",
      "everything choice happy\n",
      "unhappy sorry hear\n",
      "everything anything day\n",
      "never mind sushi\n",
      "say\n",
      "say\n",
      "i d say\n",
      "say\n",
      "say\n",
      "\n",
      "Наиболее похожие записи на 'true u waste day social medium read website hand':\n",
      "true\n",
      "true unhappy\n",
      "take social medium complain bad food\n",
      "website since long happy\n",
      "we ve select among top social medium blog\n",
      "okay tf colorful starbucks thing social medium unhappy\n",
      "post offer website happy\n",
      "day\n",
      "please read unhappy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = tfidf_vect.fit_transform(tfidf_tweets_df[\"lemma_misspell_text\"])\n",
    "similarity_matrix: cosine_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "similar_documents_amount: int = 10 \n",
    "for t, document in enumerate(tfidf_tweets_df[\"lemma_misspell_text\"]):\n",
    "    similar_indices = similarity_matrix[t].argsort()[: -similar_documents_amount - 1: -1][1: ]\n",
    "    print(f\"Наиболее похожие записи на '{document}':\")\n",
    "    \n",
    "    for j in similar_indices:\n",
    "        print(tweets_df.iloc[j][\"lemma_misspell_text\"])\n",
    "    \n",
    "    print()\n",
    "    if t == similar_documents_amount:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd68d95e-03a7-498e-b0e9-9258cecf6d51",
   "metadata": {},
   "source": [
    "* Выше представлен вариант, который учитывает дубликаты постов\n",
    "* Ниже представлен вариант, который не учитывает дубликаты постов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bef8257-9aba-40b9-99ac-7f0b3e86325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее похожие записи на 'shock hc order handover cbi':\n",
      "unhappy friendzone damn sad\n",
      "quiz industry\n",
      "bitter percent healthcare bengal\n",
      "notice anything unusual happy birthday lovely footy happy\n",
      "buy anything support canada\n",
      "thank b happy\n",
      "sudden blaze destroy bungalow\n",
      "cashswap case\n",
      "opt\n",
      "\n",
      "Наиболее похожие записи на 'cm ban plan':\n",
      "go workout get excited\n",
      "buy anything support canada\n",
      "peacefully sit read book work\n",
      "top high value member week happy\n",
      "do not\n",
      "bypass highway ban\n",
      "memorial get list\n",
      "dealer say load car return due disabled lose sad\n",
      "streaminuteg minute understanding thing still unhappy\n",
      "\n",
      "Наиболее похожие записи на 'hey everyone harry pancake maple syrup breakfast great way start day happy miss':\n",
      "hundred immigrant arrest routine us enforcement surge\n",
      "academic siege\n",
      "appreciate sentiment could not happy\n",
      "hey\n",
      "love\n",
      "always know would like one well haha\n",
      "thank recent follow happy connect happy great thursday want\n",
      "indias opaque law\n",
      "flash light pay parking\n",
      "\n",
      "Наиболее похожие записи на 'welfare':\n",
      "want kiss nose tell love sad\n",
      "yesterday face cute today face old meyer\n",
      "calcutta hc send case cbi\n",
      "centre move supreme court verdict lift shield\n",
      "cream read unhappy\n",
      "nothing ever seem look bad today\n",
      "oh\n",
      "well check\n",
      "gdp grow quarter\n",
      "\n",
      "Наиболее похожие записи на 'guy please help try smoke lettuce early salad ruin unhappy':\n",
      "italian easy spanish unhappy\n",
      "hi assist we ve update regard concern number switch unhappy please share another suitable time cont\n",
      "happy everyone happy\n",
      "mutual kesavan state fourth estate\n",
      "yet maybe year happy\n",
      "less cricketer\n",
      "oh since unhappy\n",
      "gun bjp\n",
      "happy birthday times happy\n",
      "\n",
      "Наиболее похожие записи на 'thank share iris photo really appreciate smile':\n",
      "puppy deserve well unhappy\n",
      "get majority member win seat\n",
      "also epaper\n",
      "say\n",
      "thank recent follow much appreciated happy get\n",
      "val reggae screentime riverdale would not half bad happy\n",
      "miss unhappy\n",
      "summer schools vocabulary unhappy need air please tell\n",
      "miss petite happy thursday happy look forward weekend\n",
      "\n",
      "Наиболее похожие записи на 'year old comment new ladylike videos trust troll':\n",
      "feel like environment disable people argument actually exclude many disabled people\n",
      "holly josh simply dreadful havoc must break subsurface black save will not\n",
      "sing song fully\n",
      "reunion august unhappy\n",
      "seem sell government time ago unhappy\n",
      "much appreciated happy want\n",
      "thank recent follow happy connect happy great thursday\n",
      "maa ki kiss bukhari take bullshit loser\n",
      "link seventeen yokohama concert english subs del\n",
      "\n",
      "Наиболее похожие записи на 'congratulations impressive happy':\n",
      "ready happy\n",
      "short twothird majority\n",
      "bored kandowiandg and played today making even bored unhappy\n",
      "choice cancel unhappy\n",
      "tamil nadu\n",
      "murals initiative go aaffaa\n",
      "I m road destination I m drive hope find place like stay\n",
      "appreciate sentiment could not happy\n",
      "face swap cat dog really upset unhappy\n",
      "\n",
      "Наиболее похожие записи на 'thank recent follow happy connect happy great thursday':\n",
      "virulent also epaper\n",
      "awesome make good nurse maid\n",
      "guy please help between unhappy\n",
      "thank happy\n",
      "bury alive scream head cry\n",
      "cry much feel\n",
      "thank recent follow happy connect happy want free\n",
      "thank recent follow\n",
      "tweet make cry cry\n",
      "\n",
      "Наиболее похожие записи на 'body hear everything mind say kind':\n",
      "please beautiful princess help\n",
      "hotel fire calcutta\n",
      "say\n",
      "greet cm captain mariner singh\n",
      "nasal let lightly\n",
      "do not say unhappy\n",
      "thank recent follow happy connect happy great thursday get\n",
      "really want dye do not go light\n",
      "how s quietly trial happy\n",
      "\n",
      "Наиболее похожие записи на 'true u waste day social medium read website hand':\n",
      "suuuuuuuuss scared crying\n",
      "sign carry barlow yet sad\n",
      "thank recent follow happy connect happy great thursday want\n",
      "ir would trauma ware unhappy\n",
      "iii gentleman commander bryannousaurus happy\n",
      "paddy field could blame\n",
      "girl rear monkey\n",
      "perfect dress\n",
      "play photo editor happy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = tfidf_vect.fit_transform(tfidf_tweets_df[\"lemma_misspell_text\"].drop_duplicates(keep=\"first\"))\n",
    "similarity_matrix: cosine_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "similar_documents_amount: int = 10 \n",
    "for t, document in enumerate(tfidf_tweets_df[\"lemma_misspell_text\"]):\n",
    "    similar_indices = similarity_matrix[t].argsort()[: -similar_documents_amount - 1: -1][1: ]\n",
    "    print(f\"Наиболее похожие записи на '{document}':\")\n",
    "    \n",
    "    for j in similar_indices:\n",
    "        print(tweets_df.iloc[j][\"lemma_misspell_text\"])\n",
    "    \n",
    "    print()\n",
    "    if t == similar_documents_amount:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7fd565-753a-4737-befc-1f63760e0170",
   "metadata": {},
   "source": [
    "# Totals\n",
    "\n",
    "* В процессе выполнения задания был обработан датафрейм (убраны стоп-слова (точность предсказаний без стоп-слов немного выше, чем с ними), добавлены лемматизация, стемминг, миссемплинг, мешок слов, а также tfidf и word2vec). наилучший результат предсказаний - 0.89 через логистическую регрессию на основе word2vec (результат может немного различаться ввиду случайности выборки)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
